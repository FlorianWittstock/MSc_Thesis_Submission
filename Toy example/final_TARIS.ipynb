{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS IS THE CURRENT VERSION ###\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "#set seed\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "#do same algorithm but with averaging\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats import nct\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "\n",
    "# Plot empircal distribution of markov chain\n",
    "n1,n2 = 100,100\n",
    "\n",
    "#Train and find MCMC proposal distribution\n",
    "# Generate synthetic data\n",
    "samples1 = np.random.normal(5.75, 1.5, 1000)\n",
    "samples2 = np.random.normal(9.2, 0.5, 1000)\n",
    "combined_samples = np.concatenate((samples1, samples2)).reshape(-1, 1)\n",
    "\n",
    "# Fit a Gaussian Mixture Model with 2 components\n",
    "gmm = GaussianMixture(n_components=2)\n",
    "gmm.fit(combined_samples)\n",
    "\n",
    "\n",
    "def target_function(x):\n",
    "    return min(15000,max(0,50*(x-8)**5))\n",
    "\n",
    "def TARIS_GMM_PROPOSAL(T,N):\n",
    "    y = 5\n",
    "    duration = np.arange(T)\n",
    "    first_ratio = 5\n",
    "    ratio_estimate_per_iteration = np.zeros(T)\n",
    "    ratio_estimate_averages = np.zeros(T-5)\n",
    "    ratio_estimate_per_iteration[0] = first_ratio\n",
    "    first_x = np.zeros(1)\n",
    "    for t in duration:\n",
    "        print(\"starting t at \", datetime.now())\n",
    "        x = [np.array(7.5)] #[0.5 * (np.mean(q_1_samples) + np.mean(q_2_samples))]\n",
    "        if t == 0:\n",
    "            ratio_estimate_per_iteration_now = ratio_estimate_per_iteration[0]\n",
    "            x = [np.array(7.5)]\n",
    "        else:\n",
    "            ratio_estimate_per_iteration_now = ratio_estimate_per_iteration[t-1]\n",
    "            x = [first_x]\n",
    "        length = np.arange(N)\n",
    "        for i in length:\n",
    "            if i%10000 == 0:\n",
    "                print(i) \n",
    "            #propose new X'\n",
    "            x_old = x[-1]\n",
    "            x_new = gmm.sample(1)[0][0]\n",
    "            #calculate acceptance probability\n",
    "            nom_accept = abs(target_function(x_new)-ratio_estimate_per_iteration_now) * sp.stats.gamma.pdf(x_new, a=5, loc=0, scale=4) * sp.stats.norm.pdf(y, loc=x_new, scale=1) * np.exp(gmm.score_samples(np.array(x_old).reshape(-1, 1)))\n",
    "            denom_accept = abs(target_function(x_old)-ratio_estimate_per_iteration_now) * sp.stats.gamma.pdf(x_old, a=5, loc=0, scale=4) * sp.stats.norm.pdf(y, loc=x_old, scale=1) * np.exp(gmm.score_samples(np.array(x_new).reshape(-1, 1)))\n",
    "            alpha = min(1,nom_accept/denom_accept)\n",
    "            u = np.random.uniform(low=0.0, high=1.0, size=1)\n",
    "            if u <= alpha:\n",
    "                x.append(x_new)\n",
    "                \n",
    "            elif u > alpha:\n",
    "                x.append(x_old)\n",
    "        \n",
    "        \n",
    "        x = x[1000:]\n",
    "        first_x = x[-1]          #save last x for next iteration\n",
    "        f_x_here = [target_function(entry[0]) for entry in x]\n",
    "        f_x_here = np.array(f_x_here)\n",
    "        nom_rat = np.sum(f_x_here/abs(f_x_here - ratio_estimate_per_iteration_now))\n",
    "        denom_rat = np.sum(1/abs(f_x_here - ratio_estimate_per_iteration_now))\n",
    "        r_current = nom_rat/denom_rat\n",
    "        ratio_estimate_per_iteration[t] = r_current\n",
    "        if t < 5:\n",
    "            pass\n",
    "        else:\n",
    "            r_estimates_until_now = np.concatenate((ratio_estimate_per_iteration[5:t], np.array([r_current])))\n",
    "            ratio_estimate_averages[t-5] = np.mean(r_estimates_until_now)\n",
    "        print('iteration',t+1,'is done')\n",
    "    return {'ratio_estimate_per_iteration': ratio_estimate_per_iteration, 'ratio_estimate_averages': ratio_estimate_averages}\n",
    "\n",
    "result_100 = TARIS_GMM_PROPOSAL(1000,1100)\n",
    "result_1k = TARIS_GMM_PROPOSAL(1000,2000)\n",
    "result_10k = TARIS_GMM_PROPOSAL(100,11000)\n",
    "result_100k = TARIS_GMM_PROPOSAL(100,101000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract results\n",
    "r_plot_100 = result_100['ratio_estimate_per_iteration'][5:]\n",
    "r_average_100 = result_100['ratio_estimate_averages']\n",
    "\n",
    "r_plot_1k = result_1k['ratio_estimate_per_iteration'][5:]\n",
    "r_average_1k = result_1k['ratio_estimate_averages']\n",
    "\n",
    "r_plot_10k = result_10k['ratio_estimate_per_iteration'][5:]\n",
    "r_average_10k = result_10k['ratio_estimate_averages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate relative mean squared error for averages\n",
    "\n",
    "ReMSE_10k = (r_average_10k - ground_truth)**2/ground_truth**2\n",
    "ReMSE_1k = (r_average_1k - ground_truth)**2/ground_truth**2\n",
    "ReMSE_100 = (r_average_100 - ground_truth)**2/ground_truth**2\n",
    "\n",
    "total_samples_1k = np.arange(1000, 1000*(len(r_average_1k)+1), 1000)\n",
    "total_samples_10k = np.arange(10000, 10000*(len(r_average_10k)+1), 10000)\n",
    "total_samples_100 = np.arange(100, 100*(len(r_average_100)+1), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate TABI\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "total_samples_TABI = np.unique(np.concatenate((total_samples_100, total_samples_1k, total_samples_10k)))/2\n",
    "total_samples_TABI = total_samples_TABI.astype(int)\n",
    "\n",
    "def compute_TABI(n1,n2):\n",
    "    ground_truth = 0.03283152373679992\n",
    "    q_1_samples = nct.rvs(df=10, nc=0, loc=9.3,scale=0.5, size=n1)\n",
    "    q_2_samples = np.random.normal(loc=5.4, scale=0.98, size=n2)\n",
    "\n",
    "    joint_q1 = sp.stats.gamma.pdf(q_1_samples, a=5, loc=0, scale=4) * sp.stats.norm.pdf(5, loc=q_1_samples, scale=1)\n",
    "    joint_q2 = sp.stats.gamma.pdf(q_2_samples, a=5, loc=0, scale=4) * sp.stats.norm.pdf(5, loc=q_2_samples, scale=1)\n",
    "\n",
    "    def target_function(x):\n",
    "        return min(15000,max(0,50*(x-8)**5))\n",
    "    \n",
    "    target_function_q1 = np.array(list(map(target_function, q_1_samples)))\n",
    "\n",
    "    q_1_density = nct.pdf(q_1_samples,df=10, nc=0, loc=9.3,scale=0.5)\n",
    "    q_2_density = sp.stats.norm.pdf(q_2_samples, loc=5.4, scale=0.98)\n",
    "\n",
    "    nominator = 1/n1 * np.sum(target_function_q1 * joint_q1/q_1_density)\n",
    "    denominator = 1/n2 * np.sum(joint_q2/q_2_density)\n",
    "    ratio = nominator/denominator\n",
    "    ReMSE = (ratio - ground_truth)**2/ground_truth**2\n",
    "\n",
    "    return {'ratio': ratio, 'ReMSE': ReMSE}\n",
    "\n",
    "results_TABI = {n: compute_TABI(n, n) for n in total_samples_TABI}\n",
    "\n",
    "#extract results and ReMSE\n",
    "Re_MSEs_TABI = [results_TABI[n]['ReMSE'] for n in total_samples_TABI]\n",
    "ReMSE_TABI = np.array(Re_MSEs_TABI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When is TARIS_1k competitive with TABI?\n",
    "\n",
    "# Find common sample sizes\n",
    "common_sample_sizes = np.intersect1d(total_samples_1k, total_samples_TABI)\n",
    "\n",
    "# Get common ReMSE values\n",
    "common_ReMSE_1k = ReMSE_1k[np.isin(total_samples_1k, common_sample_sizes)]\n",
    "common_ReMSE_TABI = ReMSE_TABI[np.isin(total_samples_TABI, common_sample_sizes)]\n",
    "\n",
    "# Determine which method performs better for each common sample size\n",
    "winning_method = [\"1k\" if common_ReMSE_1k[i] < common_ReMSE_TABI[i] else \"TABI\" for i in range(len(common_sample_sizes))]\n",
    "\n",
    "# Extract the sample sizes where 1k beats TABI\n",
    "sample_sizes_where_1k_beats_TABI = common_sample_sizes[np.array(winning_method) == \"1k\"]\n",
    "\n",
    "print(\"TARIS_MCMC_1k beats TABI for the following common sample sizes:\", sample_sizes_where_1k_beats_TABI)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
